{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, pathlib\n",
    "#setting the path to folder with modules\n",
    "sys.path.insert(0, str(pathlib.Path(os.getcwd()).parents[1] / 'python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import sys, os, copy\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "#import libraries for file checking\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "#importing json (data are mostly in JSON)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FileAddress_movies =\"../../Datasets/tmdb_5000_movies.csv\"\n",
    "FileAddress_credits=\"../../Datasets/tmdb_5000_credits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Load_Datasets(FileAddress_movies,FileAddress_credits):\n",
    "    ##input: location of files\n",
    "    ##output: pandas dataframe containing all information on movies and credits\n",
    "    \n",
    "    def InputFilesFound(FileAddress):\n",
    "        ##input:  file location\n",
    "        ##output: True if file found, False otherwise\n",
    "        return isfile(FileAddress) and not isdir(FileAddress)\n",
    "    \n",
    "    def Transform_LoadJSON(dataframe):\n",
    "        ##input:  dataframe\n",
    "        ##output: datafreme which JSON columns transformed     \n",
    "        #itterating through JSON columns and loading json \n",
    "        JSONcolumns = IdentifyJSONcolumns(dataframe)\n",
    "        for column in JSONcolumns:\n",
    "            dataframe[column] = dataframe[column].apply(json.loads)\n",
    "        return dataframe,JSONcolumns\n",
    "    \n",
    "    def IdentifyJSONcolumns(dataframe):\n",
    "        ##input: dataframe \n",
    "        ##output: list of columns containing JSON  \n",
    "        #getting list of collumn names\n",
    "        columns=list(dataframe)\n",
    "        JSONcolumns=[]\n",
    "        #itteration though columns to find those with JSON\n",
    "        for column in columns:\n",
    "            try:\n",
    "                json.loads(dataframe[column][0]) \n",
    "            except: continue\n",
    "            JSONcolumns.append(column)   \n",
    "        #returning list of columns in which JSON format was found\n",
    "        return JSONcolumns\n",
    "    \n",
    "    def JSONtoKeyList(JSONentry,key):\n",
    "        \n",
    "        INNERentries = []\n",
    "        for InnerEntry in JSONentry:\n",
    "            INNERentries.append(InnerEntry[key])\n",
    "        if len(JSONentry)>0:\n",
    "            if key =='gender':\n",
    "                outcome=''\n",
    "                for entry in INNERentries:\n",
    "                    outcome.join(str(entry))\n",
    "                return  outcome\n",
    "            else:\n",
    "                return  ','.join(INNERentries)\n",
    "        return ''\n",
    "        \n",
    "        \n",
    "    \n",
    "    def JSONtoNameList(JSONentry):\n",
    "        ##input: entry (one line) from JSON one of JSON columns\n",
    "        ##output: strings of entries separated by commas\n",
    "        return JSONtoKeyList(JSONentry,'name')\n",
    "    \n",
    "    def JSONtoGenderList(JSONentry):\n",
    "        return JSONtoKeyList(JSONentry,'gender')\n",
    "        \n",
    "        \n",
    "    def Transform_JSONcolumnsDecapsulation(dataframe):\n",
    "        ##input: dataframe\n",
    "        ##output: dataframe which JSON columns decapsulated\n",
    "        \n",
    "        def GetJSONkeys(JSONunit):\n",
    "            ##input: JSON data unit\n",
    "            ##output: List of keys in the JSON dictionary\n",
    "            JSONkeys=[]\n",
    "            for key in JSONunit:\n",
    "                JSONkeys.append(key)\n",
    "            return JSONkeys   \n",
    "    \n",
    "   \n",
    "        def Accesor(bucket, locator):\n",
    "            ##input: values to be read safely, index value in list\n",
    "            ##output: value (if exists), otherwise nan\n",
    "            try:\n",
    "                return bucket[locator]\n",
    "            except IndexError or KeyError:\n",
    "                return pd.np.nan\n",
    "           \n",
    "        #allowing for changes of passed datased\n",
    "        dataframe.is_copy = False \n",
    "        #reading JSON format and columns\n",
    "        dataframe,JSONcolumns = Transform_LoadJSON(dataframe)\n",
    "        #transforming JSON columns to text columns\n",
    "        for column in JSONcolumns:\n",
    "            dataframe[column] =dataframe[column].apply(JSONtoNameList)\n",
    "        return dataframe\n",
    "\n",
    "    #Loading movies from file to dataframe\n",
    "    def Load_movies(FileAddress_movies):\n",
    "        ##input:  movie dataset location\n",
    "        ##output: pandas Frame containing information about movies\n",
    "        #reading raw dataset\n",
    "        df_movies = pd.read_csv(FileAddress_movies)\n",
    "        #decaplsulating json, making columns from list keys\n",
    "        df_movies = Transform_JSONcolumnsDecapsulation(df_movies)\n",
    "        return df_movies\n",
    "    \n",
    "    def Load_credits(FileAddress_credits):\n",
    "        df_credits = pd.read_csv(FileAddress_credits)\n",
    "        df_credits = Transform_LoadJSON(df_credits)\n",
    "        \n",
    "        credits = pd.DataFrame()\n",
    "        \n",
    "        credits['title'] = df_credits[0]['title']\n",
    "        credits['actors']  = df_credits[0]['cast'].apply(JSONtoNameList)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #df_credits[0]['actor_gender']  = df_credits[0]['cast'].apply(JSONtoGenderList)\n",
    "        \n",
    "        #credits      = credits.join(actors, how='outer')\n",
    "        #for cast in df_credits[0]['cast']:\n",
    "         #   Actors =JSONtoGenderList(cast)\n",
    "            #for actor in cast:\n",
    "            #    break\n",
    "                #Actors =[]\n",
    "          #  break\n",
    "        print(credits.tail(5))\n",
    "             \n",
    "       \n",
    "        return credits\n",
    "    \n",
    "    #assuring that both dataset exists\n",
    "    assert InputFilesFound(FileAddress_movies),  \"Movies  input file not found\"\n",
    "    assert InputFilesFound(FileAddress_credits), \"Credits input file not found\"\n",
    "    \n",
    "    Credentials = Load_credits(FileAddress_credits)\n",
    "    Final_dataset=Load_movies(FileAddress_movies)\n",
    "    \n",
    "    #returning final dataset\n",
    "    return Final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          title  \\\n",
      "4798                El Mariachi   \n",
      "4799                  Newlyweds   \n",
      "4800  Signed, Sealed, Delivered   \n",
      "4801           Shanghai Calling   \n",
      "4802          My Date with Drew   \n",
      "\n",
      "                                                 actors  \n",
      "4798  Carlos Gallardo,Jaime de Hoyos,Peter Marquardt...  \n",
      "4799  Edward Burns,Kerry Bish√©,Marsha Dietlein,Caitl...  \n",
      "4800  Eric Mabius,Kristin Booth,Crystal Lowe,Geoff G...  \n",
      "4801  Daniel Henney,Eliza Coupe,Bill Paxton,Alan Ruc...  \n",
      "4802  Drew Barrymore,Brian Herzlinger,Corey Feldman,...  \n"
     ]
    }
   ],
   "source": [
    "#Loading information about movies\n",
    "Movies  = Load_Datasets(FileAddress_movies,FileAddress_credits)\n",
    "\n",
    "Drops = ['homepage','status','id']\n",
    "for drop in Drops:\n",
    "    Movies = Movies.drop(drop, 1)\n",
    "        \n",
    "    \n",
    "\n",
    "Movies.to_csv(\"../../Datasets/Transformed.csv\")\n",
    "#print(Movies.dtypes)\n",
    "#read arrays from string using string.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
